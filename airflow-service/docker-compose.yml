name: airflow-service

volumes:
  pg_data: {}
  secrets_cache: {}

networks:
  airflow_net:
    name: airflow_net
    external: true
  infra_net:
    name: infra_net
    external: true

services:
  postgres:
    image: postgres:17
    container_name: airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_DB: airflow
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./secrets/postgres_password.txt:/run/secrets/postgres_password:ro
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 5s
      timeout: 5s
      retries: 20
    networks:
      - airflow_net
      - infra_net

  init-secrets:
    image: postgres:17
    container_name: airflow-init-secrets
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      PGHOST: postgres
      PGUSER: airflow
      PGDATABASE: airflow
      PGPASSWORD_FILE: /run/secrets/postgres_password
    volumes:
      - ./secrets/postgres_password.txt:/run/secrets/postgres_password:ro
      - secrets_cache:/secrets_out
      - ./scripts/init-secrets.sh:/docker-entrypoint-initdb.d/99-init-secrets.sh:ro
    entrypoint: [ "bash", "-lc", "/docker-entrypoint-initdb.d/99-init-secrets.sh" ]
    restart: "no"
    networks:
      - airflow_net
      - infra_net

  airflow:
    image: apache/airflow:latest
    container_name: airflow
    depends_on:
      postgres:
        condition: service_healthy
      init-secrets:
        condition: service_completed_successfully
    ports:
      - "8080:8080"
    environment:
      AIRFLOW_UID: "50000"
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__STORE_SERIALIZED_DAGS: "True"
      AIRFLOW__CORE__MIN_SERIALIZED_DAG_UPDATE_INTERVAL: "5"
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: "10"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN_CMD: >
        bash -lc 'printf %s "postgresql+psycopg2://airflow:$(cat /run/secrets/postgres_password)@postgres:5432/airflow"'
      AIRFLOW__CORE__FERNET_KEY_CMD: >
        bash -lc 'printf %s "$(cat /run/airflow-secrets/fernet_key)"'
      AIRFLOW__API__SECRET_KEY_CMD: >
        bash -lc 'printf %s "$(cat /run/airflow-secrets/webserver_secret_key)"'
      AIRFLOW__CORE__SIMPLE_AUTH_MANAGER_PASSWORDS_FILE: "/opt/airflow/simple_auth_manager_passwords.json"
    volumes:
      - ./airflow-home/dags:/opt/airflow/dags
      - ./airflow-home/logs:/opt/airflow/logs
      - ./airflow-home/plugins:/opt/airflow/plugins
      - ./secrets/postgres_password.txt:/run/secrets/postgres_password:ro
      - secrets_cache:/run/airflow-secrets:ro
    command: |
      bash -lc '
        set -euo pipefail

        mkdir -p /opt/airflow/dags /opt/airflow/logs /opt/airflow/plugins

        # Read admin creds produced by init-secrets
        ADMIN_USER="$(tr -d "\n" < /run/airflow-secrets/admin_user || true)"
        ADMIN_PASS="$(tr -d "\n" < /run/airflow-secrets/admin_password || true)"

        if [ -z "$${ADMIN_USER}" ] || [ -z "$${ADMIN_PASS}" ]; then
          echo "ERROR: /run/airflow-secrets/admin_user or admin_password missing"
          ls -lah /run/airflow-secrets || true
          exit 1
        fi

        # Write the SimpleAuth file (single-line JSON)
        printf "{\"%s\":\"%s\"}" "$${ADMIN_USER}" "$${ADMIN_PASS}" > /opt/airflow/simple_auth_manager_passwords.json
        chmod 600 /opt/airflow/simple_auth_manager_passwords.json || true

        # DB migrate and start services (Airflow 3)
        airflow db migrate
        airflow dag-processor &
        airflow scheduler &
        airflow triggerer &

        exec airflow api-server --port 8080
      '
    restart: unless-stopped
    networks:
      - airflow_net
      - infra_net